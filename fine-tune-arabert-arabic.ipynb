{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.11","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":11925786,"sourceType":"datasetVersion","datasetId":7497979}],"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"!pip install transformers datasets torch wandb\n!pip install pyarabic farasapy arabert","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-23T22:49:04.218213Z","iopub.execute_input":"2025-05-23T22:49:04.218468Z","iopub.status.idle":"2025-05-23T22:50:35.516338Z","shell.execute_reply.started":"2025-05-23T22:49:04.218440Z","shell.execute_reply":"2025-05-23T22:50:35.515263Z"}},"outputs":[{"name":"stdout","text":"Requirement already satisfied: transformers in /usr/local/lib/python3.11/dist-packages (4.51.3)\nRequirement already satisfied: datasets in /usr/local/lib/python3.11/dist-packages (3.6.0)\nRequirement already satisfied: torch in /usr/local/lib/python3.11/dist-packages (2.6.0+cu124)\nRequirement already satisfied: wandb in /usr/local/lib/python3.11/dist-packages (0.19.9)\nRequirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from transformers) (3.18.0)\nRequirement already satisfied: huggingface-hub<1.0,>=0.30.0 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.31.1)\nRequirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.11/dist-packages (from transformers) (1.26.4)\nRequirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from transformers) (25.0)\nRequirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from transformers) (6.0.2)\nRequirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.11/dist-packages (from transformers) (2024.11.6)\nRequirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from transformers) (2.32.3)\nRequirement already satisfied: tokenizers<0.22,>=0.21 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.21.1)\nRequirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.5.3)\nRequirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.11/dist-packages (from transformers) (4.67.1)\nRequirement already satisfied: pyarrow>=15.0.0 in /usr/local/lib/python3.11/dist-packages (from datasets) (19.0.1)\nRequirement already satisfied: dill<0.3.9,>=0.3.0 in /usr/local/lib/python3.11/dist-packages (from datasets) (0.3.8)\nRequirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (from datasets) (2.2.3)\nRequirement already satisfied: xxhash in /usr/local/lib/python3.11/dist-packages (from datasets) (3.5.0)\nRequirement already satisfied: multiprocess<0.70.17 in /usr/local/lib/python3.11/dist-packages (from datasets) (0.70.16)\nCollecting fsspec<=2025.3.0,>=2023.1.0 (from fsspec[http]<=2025.3.0,>=2023.1.0->datasets)\n  Downloading fsspec-2025.3.0-py3-none-any.whl.metadata (11 kB)\nRequirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.11/dist-packages (from torch) (4.13.2)\nRequirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch) (3.4.2)\nRequirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch) (3.1.6)\nRequirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\nRequirement already satisfied: nvidia-cuda-runtime-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\nRequirement already satisfied: nvidia-cuda-cupti-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\nCollecting nvidia-cudnn-cu12==9.1.0.70 (from torch)\n  Downloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\nCollecting nvidia-cublas-cu12==12.4.5.8 (from torch)\n  Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\nCollecting nvidia-cufft-cu12==11.2.1.3 (from torch)\n  Downloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\nCollecting nvidia-curand-cu12==10.3.5.147 (from torch)\n  Downloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\nCollecting nvidia-cusolver-cu12==11.6.1.9 (from torch)\n  Downloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\nCollecting nvidia-cusparse-cu12==12.3.1.170 (from torch)\n  Downloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\nRequirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch) (0.6.2)\nRequirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch) (2.21.5)\nRequirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\nCollecting nvidia-nvjitlink-cu12==12.4.127 (from torch)\n  Downloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\nRequirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch) (3.2.0)\nRequirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch) (1.13.1)\nRequirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch) (1.3.0)\nRequirement already satisfied: click!=8.0.0,>=7.1 in /usr/local/lib/python3.11/dist-packages (from wandb) (8.1.8)\nRequirement already satisfied: docker-pycreds>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from wandb) (0.4.0)\nRequirement already satisfied: gitpython!=3.1.29,>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from wandb) (3.1.44)\nRequirement already satisfied: platformdirs in /usr/local/lib/python3.11/dist-packages (from wandb) (4.3.8)\nRequirement already satisfied: protobuf!=4.21.0,!=5.28.0,<6,>=3.19.0 in /usr/local/lib/python3.11/dist-packages (from wandb) (3.20.3)\nRequirement already satisfied: psutil>=5.0.0 in /usr/local/lib/python3.11/dist-packages (from wandb) (7.0.0)\nRequirement already satisfied: pydantic<3 in /usr/local/lib/python3.11/dist-packages (from wandb) (2.11.4)\nRequirement already satisfied: sentry-sdk>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from wandb) (2.25.1)\nRequirement already satisfied: setproctitle in /usr/local/lib/python3.11/dist-packages (from wandb) (1.3.5)\nRequirement already satisfied: setuptools in /usr/local/lib/python3.11/dist-packages (from wandb) (75.2.0)\nRequirement already satisfied: six>=1.4.0 in /usr/local/lib/python3.11/dist-packages (from docker-pycreds>=0.4.0->wandb) (1.17.0)\nRequirement already satisfied: aiohttp!=4.0.0a0,!=4.0.0a1 in /usr/local/lib/python3.11/dist-packages (from fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (3.11.18)\nRequirement already satisfied: gitdb<5,>=4.0.1 in /usr/local/lib/python3.11/dist-packages (from gitpython!=3.1.29,>=1.0.0->wandb) (4.0.12)\nRequirement already satisfied: hf-xet<2.0.0,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.30.0->transformers) (1.1.0)\nRequirement already satisfied: mkl_fft in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->transformers) (1.3.8)\nRequirement already satisfied: mkl_random in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->transformers) (1.2.4)\nRequirement already satisfied: mkl_umath in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->transformers) (0.1.1)\nRequirement already satisfied: mkl in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->transformers) (2025.1.0)\nRequirement already satisfied: tbb4py in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->transformers) (2022.1.0)\nRequirement already satisfied: mkl-service in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->transformers) (2.4.1)\nRequirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3->wandb) (0.7.0)\nRequirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.11/dist-packages (from pydantic<3->wandb) (2.33.2)\nRequirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3->wandb) (0.4.0)\nRequirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (3.4.2)\nRequirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (3.10)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (2.4.0)\nRequirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (2025.4.26)\nRequirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch) (3.0.2)\nRequirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets) (2.9.0.post0)\nRequirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets) (2025.2)\nRequirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets) (2025.2)\nRequirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (2.6.1)\nRequirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (1.3.2)\nRequirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (25.3.0)\nRequirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (1.6.0)\nRequirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (6.4.3)\nRequirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (0.3.1)\nRequirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (1.20.0)\nRequirement already satisfied: smmap<6,>=3.0.1 in /usr/local/lib/python3.11/dist-packages (from gitdb<5,>=4.0.1->gitpython!=3.1.29,>=1.0.0->wandb) (5.0.2)\nRequirement already satisfied: intel-openmp<2026,>=2024 in /usr/local/lib/python3.11/dist-packages (from mkl->numpy>=1.17->transformers) (2024.2.0)\nRequirement already satisfied: tbb==2022.* in /usr/local/lib/python3.11/dist-packages (from mkl->numpy>=1.17->transformers) (2022.1.0)\nRequirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.11/dist-packages (from tbb==2022.*->mkl->numpy>=1.17->transformers) (1.3.0)\nRequirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.11/dist-packages (from mkl_umath->numpy>=1.17->transformers) (2024.2.0)\nRequirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.11/dist-packages (from intel-openmp<2026,>=2024->mkl->numpy>=1.17->transformers) (2024.2.0)\nDownloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl (363.4 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m4.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m0:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl (664.8 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m2.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m0:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl (211.5 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m2.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m0:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl (56.3 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m29.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl (127.9 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m12.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl (207.5 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m7.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m0:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (21.1 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m68.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading fsspec-2025.3.0-py3-none-any.whl (193 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m193.6/193.6 kB\u001b[0m \u001b[31m13.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hInstalling collected packages: nvidia-nvjitlink-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cublas-cu12, fsspec, nvidia-cusparse-cu12, nvidia-cudnn-cu12, nvidia-cusolver-cu12\n  Attempting uninstall: nvidia-nvjitlink-cu12\n    Found existing installation: nvidia-nvjitlink-cu12 12.9.41\n    Uninstalling nvidia-nvjitlink-cu12-12.9.41:\n      Successfully uninstalled nvidia-nvjitlink-cu12-12.9.41\n  Attempting uninstall: nvidia-curand-cu12\n    Found existing installation: nvidia-curand-cu12 10.3.10.19\n    Uninstalling nvidia-curand-cu12-10.3.10.19:\n      Successfully uninstalled nvidia-curand-cu12-10.3.10.19\n  Attempting uninstall: nvidia-cufft-cu12\n    Found existing installation: nvidia-cufft-cu12 11.4.0.6\n    Uninstalling nvidia-cufft-cu12-11.4.0.6:\n      Successfully uninstalled nvidia-cufft-cu12-11.4.0.6\n  Attempting uninstall: nvidia-cublas-cu12\n    Found existing installation: nvidia-cublas-cu12 12.9.0.13\n    Uninstalling nvidia-cublas-cu12-12.9.0.13:\n      Successfully uninstalled nvidia-cublas-cu12-12.9.0.13\n  Attempting uninstall: fsspec\n    Found existing installation: fsspec 2025.3.2\n    Uninstalling fsspec-2025.3.2:\n      Successfully uninstalled fsspec-2025.3.2\n  Attempting uninstall: nvidia-cusparse-cu12\n    Found existing installation: nvidia-cusparse-cu12 12.5.9.5\n    Uninstalling nvidia-cusparse-cu12-12.5.9.5:\n      Successfully uninstalled nvidia-cusparse-cu12-12.5.9.5\n  Attempting uninstall: nvidia-cudnn-cu12\n    Found existing installation: nvidia-cudnn-cu12 9.3.0.75\n    Uninstalling nvidia-cudnn-cu12-9.3.0.75:\n      Successfully uninstalled nvidia-cudnn-cu12-9.3.0.75\n  Attempting uninstall: nvidia-cusolver-cu12\n    Found existing installation: nvidia-cusolver-cu12 11.7.4.40\n    Uninstalling nvidia-cusolver-cu12-11.7.4.40:\n      Successfully uninstalled nvidia-cusolver-cu12-11.7.4.40\n\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\ncesium 0.12.4 requires numpy<3.0,>=2.0, but you have numpy 1.26.4 which is incompatible.\nbigframes 1.42.0 requires rich<14,>=12.4.4, but you have rich 14.0.0 which is incompatible.\ngcsfs 2025.3.2 requires fsspec==2025.3.2, but you have fsspec 2025.3.0 which is incompatible.\u001b[0m\u001b[31m\n\u001b[0mSuccessfully installed fsspec-2025.3.0 nvidia-cublas-cu12-12.4.5.8 nvidia-cudnn-cu12-9.1.0.70 nvidia-cufft-cu12-11.2.1.3 nvidia-curand-cu12-10.3.5.147 nvidia-cusolver-cu12-11.6.1.9 nvidia-cusparse-cu12-12.3.1.170 nvidia-nvjitlink-cu12-12.4.127\nRequirement already satisfied: pyarabic in /usr/local/lib/python3.11/dist-packages (0.6.15)\nCollecting farasapy\n  Downloading farasapy-0.0.14-py3-none-any.whl.metadata (8.9 kB)\nCollecting arabert\n  Downloading arabert-1.0.1-py3-none-any.whl.metadata (16 kB)\nRequirement already satisfied: six>=1.14.0 in /usr/local/lib/python3.11/dist-packages (from pyarabic) (1.17.0)\nRequirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from farasapy) (2.32.3)\nRequirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from farasapy) (4.67.1)\nCollecting emoji==1.4.2 (from arabert)\n  Downloading emoji-1.4.2.tar.gz (184 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m185.0/185.0 kB\u001b[0m \u001b[31m3.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m\n\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\nRequirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->farasapy) (3.4.2)\nRequirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->farasapy) (3.10)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->farasapy) (2.4.0)\nRequirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->farasapy) (2025.4.26)\nDownloading farasapy-0.0.14-py3-none-any.whl (11 kB)\nDownloading arabert-1.0.1-py3-none-any.whl (179 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m179.3/179.3 kB\u001b[0m \u001b[31m9.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hBuilding wheels for collected packages: emoji\n  Building wheel for emoji (setup.py) ... \u001b[?25l\u001b[?25hdone\n  Created wheel for emoji: filename=emoji-1.4.2-py3-none-any.whl size=186456 sha256=c8e7032f6d26465fc9c5aae43b4f52801f321ae91d57d43bf8b1b1ce7ba309e9\n  Stored in directory: /root/.cache/pip/wheels/94/08/b4/78657b1541bb704b088317b52429ee4016d9888fe47dbb130f\nSuccessfully built emoji\nInstalling collected packages: emoji, farasapy, arabert\n  Attempting uninstall: emoji\n    Found existing installation: emoji 2.14.1\n    Uninstalling emoji-2.14.1:\n      Successfully uninstalled emoji-2.14.1\nSuccessfully installed arabert-1.0.1 emoji-1.4.2 farasapy-0.0.14\n","output_type":"stream"}],"execution_count":1},{"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nfrom sklearn.model_selection import train_test_split\nimport collections\nfrom collections import Counter","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-23T22:50:35.518224Z","iopub.execute_input":"2025-05-23T22:50:35.518481Z","iopub.status.idle":"2025-05-23T22:50:36.462745Z","shell.execute_reply.started":"2025-05-23T22:50:35.518456Z","shell.execute_reply":"2025-05-23T22:50:36.461935Z"}},"outputs":[],"execution_count":2},{"cell_type":"code","source":"df=pd.read_csv(\"/kaggle/input/hotel-reviewsarabic/balanced-reviews.txt\",sep=\"\\t\",encoding=\"utf-16\")\ndf.head()","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-05-23T22:50:36.463450Z","iopub.execute_input":"2025-05-23T22:50:36.463791Z","iopub.status.idle":"2025-05-23T22:50:37.916954Z","shell.execute_reply.started":"2025-05-23T22:50:36.463772Z","shell.execute_reply":"2025-05-23T22:50:37.916293Z"}},"outputs":[{"execution_count":3,"output_type":"execute_result","data":{"text/plain":"   no Hotel name  rating    user type                   room type  \\\n0   2    فندق 72       2  مسافر منفرد  غرفة ديلوكس مزدوجة أو توأم   \n1   3    فندق 72       5          زوج  غرفة ديلوكس مزدوجة أو توأم   \n2  16    فندق 72       5          زوج                           -   \n3  20    فندق 72       1          زوج          غرفة قياسية مزدوجة   \n4  23    فندق 72       4          زوج  غرفة ديلوكس مزدوجة أو توأم   \n\n            nights                                             review  \n0  أقمت ليلة واحدة                  “ممتاز”. النظافة والطاقم متعاون.   \n1  أقمت ليلة واحدة  استثنائي. سهولة إنهاء المعاملة في الاستقبال. ل...  \n2      أقمت ليلتين  استثنائي. انصح بأختيار الاسويت و بالاخص غرفه ر...  \n3  أقمت ليلة واحدة  “استغرب تقييم الفندق كخمس نجوم”. لا شي. يستحق ...  \n4      أقمت ليلتين  جيد. المكان جميل وهاديء. كل شي جيد ونظيف بس كا...  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>no</th>\n      <th>Hotel name</th>\n      <th>rating</th>\n      <th>user type</th>\n      <th>room type</th>\n      <th>nights</th>\n      <th>review</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>2</td>\n      <td>فندق 72</td>\n      <td>2</td>\n      <td>مسافر منفرد</td>\n      <td>غرفة ديلوكس مزدوجة أو توأم</td>\n      <td>أقمت ليلة واحدة</td>\n      <td>“ممتاز”. النظافة والطاقم متعاون.</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>3</td>\n      <td>فندق 72</td>\n      <td>5</td>\n      <td>زوج</td>\n      <td>غرفة ديلوكس مزدوجة أو توأم</td>\n      <td>أقمت ليلة واحدة</td>\n      <td>استثنائي. سهولة إنهاء المعاملة في الاستقبال. ل...</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>16</td>\n      <td>فندق 72</td>\n      <td>5</td>\n      <td>زوج</td>\n      <td>-</td>\n      <td>أقمت ليلتين</td>\n      <td>استثنائي. انصح بأختيار الاسويت و بالاخص غرفه ر...</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>20</td>\n      <td>فندق 72</td>\n      <td>1</td>\n      <td>زوج</td>\n      <td>غرفة قياسية مزدوجة</td>\n      <td>أقمت ليلة واحدة</td>\n      <td>“استغرب تقييم الفندق كخمس نجوم”. لا شي. يستحق ...</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>23</td>\n      <td>فندق 72</td>\n      <td>4</td>\n      <td>زوج</td>\n      <td>غرفة ديلوكس مزدوجة أو توأم</td>\n      <td>أقمت ليلتين</td>\n      <td>جيد. المكان جميل وهاديء. كل شي جيد ونظيف بس كا...</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}],"execution_count":3},{"cell_type":"code","source":"mydf=df[['review','rating']]\nmydf","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-23T22:50:37.917775Z","iopub.execute_input":"2025-05-23T22:50:37.918091Z","iopub.status.idle":"2025-05-23T22:50:37.936982Z","shell.execute_reply.started":"2025-05-23T22:50:37.918069Z","shell.execute_reply":"2025-05-23T22:50:37.936295Z"}},"outputs":[{"execution_count":4,"output_type":"execute_result","data":{"text/plain":"                                                   review  rating\n0                       “ممتاز”. النظافة والطاقم متعاون.        2\n1       استثنائي. سهولة إنهاء المعاملة في الاستقبال. ل...       5\n2       استثنائي. انصح بأختيار الاسويت و بالاخص غرفه ر...       5\n3       “استغرب تقييم الفندق كخمس نجوم”. لا شي. يستحق ...       1\n4       جيد. المكان جميل وهاديء. كل شي جيد ونظيف بس كا...       4\n...                                                   ...     ...\n105693  “فند”. لا شئ عجبني. طقم العمل سيئ جدالا يوجد ب...       1\n105694  “سيئ”. قربه من المسجد النبوي الشريف. استخدام م...       2\n105695  “اسوأ إقامة في الرحلة !”. القرب من الحرم. كل ش...       2\n105696               “دون المستوى”. قربه من الحرم. كل شيء       2\n105697  مخيب للأمل. . سوء التنسيق من حيث معرفة الغرف ب...       2\n\n[105698 rows x 2 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>review</th>\n      <th>rating</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>“ممتاز”. النظافة والطاقم متعاون.</td>\n      <td>2</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>استثنائي. سهولة إنهاء المعاملة في الاستقبال. ل...</td>\n      <td>5</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>استثنائي. انصح بأختيار الاسويت و بالاخص غرفه ر...</td>\n      <td>5</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>“استغرب تقييم الفندق كخمس نجوم”. لا شي. يستحق ...</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>جيد. المكان جميل وهاديء. كل شي جيد ونظيف بس كا...</td>\n      <td>4</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>105693</th>\n      <td>“فند”. لا شئ عجبني. طقم العمل سيئ جدالا يوجد ب...</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>105694</th>\n      <td>“سيئ”. قربه من المسجد النبوي الشريف. استخدام م...</td>\n      <td>2</td>\n    </tr>\n    <tr>\n      <th>105695</th>\n      <td>“اسوأ إقامة في الرحلة !”. القرب من الحرم. كل ش...</td>\n      <td>2</td>\n    </tr>\n    <tr>\n      <th>105696</th>\n      <td>“دون المستوى”. قربه من الحرم. كل شيء</td>\n      <td>2</td>\n    </tr>\n    <tr>\n      <th>105697</th>\n      <td>مخيب للأمل. . سوء التنسيق من حيث معرفة الغرف ب...</td>\n      <td>2</td>\n    </tr>\n  </tbody>\n</table>\n<p>105698 rows × 2 columns</p>\n</div>"},"metadata":{}}],"execution_count":4},{"cell_type":"code","source":"count=Counter(mydf['rating'])\ncount","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-23T22:50:37.939161Z","iopub.execute_input":"2025-05-23T22:50:37.939369Z","iopub.status.idle":"2025-05-23T22:50:37.960453Z","shell.execute_reply.started":"2025-05-23T22:50:37.939353Z","shell.execute_reply":"2025-05-23T22:50:37.959760Z"}},"outputs":[{"execution_count":5,"output_type":"execute_result","data":{"text/plain":"Counter({2: 38467, 5: 26399, 1: 14382, 4: 26450})"},"metadata":{}}],"execution_count":5},{"cell_type":"code","source":"mydf['rating']=df['rating'].apply(lambda x: 1 if x>3 else 0)\nmydf.head()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-23T22:50:37.961257Z","iopub.execute_input":"2025-05-23T22:50:37.961442Z","iopub.status.idle":"2025-05-23T22:50:38.014577Z","shell.execute_reply.started":"2025-05-23T22:50:37.961426Z","shell.execute_reply":"2025-05-23T22:50:38.013771Z"}},"outputs":[{"name":"stderr","text":"/tmp/ipykernel_35/317830304.py:1: SettingWithCopyWarning: \nA value is trying to be set on a copy of a slice from a DataFrame.\nTry using .loc[row_indexer,col_indexer] = value instead\n\nSee the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n  mydf['rating']=df['rating'].apply(lambda x: 1 if x>3 else 0)\n","output_type":"stream"},{"execution_count":6,"output_type":"execute_result","data":{"text/plain":"                                              review  rating\n0                  “ممتاز”. النظافة والطاقم متعاون.        0\n1  استثنائي. سهولة إنهاء المعاملة في الاستقبال. ل...       1\n2  استثنائي. انصح بأختيار الاسويت و بالاخص غرفه ر...       1\n3  “استغرب تقييم الفندق كخمس نجوم”. لا شي. يستحق ...       0\n4  جيد. المكان جميل وهاديء. كل شي جيد ونظيف بس كا...       1","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>review</th>\n      <th>rating</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>“ممتاز”. النظافة والطاقم متعاون.</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>استثنائي. سهولة إنهاء المعاملة في الاستقبال. ل...</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>استثنائي. انصح بأختيار الاسويت و بالاخص غرفه ر...</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>“استغرب تقييم الفندق كخمس نجوم”. لا شي. يستحق ...</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>جيد. المكان جميل وهاديء. كل شي جيد ونظيف بس كا...</td>\n      <td>1</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}],"execution_count":6},{"cell_type":"code","source":"from sklearn.utils import shuffle\n\ndef pick_samples(num_samples,data):\n    pos_data=data[data['rating']==1].sample(n=min(num_samples//2,len(data[data['rating']==1])),random_state=42)\n\n    neg_data=data[data['rating']==0].sample(n=min(num_samples//2,len(data[data['rating']==0])),random_state=42)\n                                            \n    df=pd.concat([pos_data,neg_data]).reset_index(drop=True)\n    df=df.sample(frac=1,random_state=42)\n    #or use shuffle from sklearn.utild like:\n    #df=shuffle(df,random_state=42)\n    return df\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-23T22:50:38.015547Z","iopub.execute_input":"2025-05-23T22:50:38.015834Z","iopub.status.idle":"2025-05-23T22:50:38.021294Z","shell.execute_reply.started":"2025-05-23T22:50:38.015803Z","shell.execute_reply":"2025-05-23T22:50:38.020543Z"}},"outputs":[],"execution_count":7},{"cell_type":"code","source":"final_df=pick_samples(2000,mydf)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-23T22:50:38.022031Z","iopub.execute_input":"2025-05-23T22:50:38.022342Z","iopub.status.idle":"2025-05-23T22:50:38.058022Z","shell.execute_reply.started":"2025-05-23T22:50:38.022315Z","shell.execute_reply":"2025-05-23T22:50:38.057384Z"}},"outputs":[],"execution_count":8},{"cell_type":"code","source":"final_df","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-23T22:50:38.058661Z","iopub.execute_input":"2025-05-23T22:50:38.058883Z","iopub.status.idle":"2025-05-23T22:50:38.067241Z","shell.execute_reply.started":"2025-05-23T22:50:38.058866Z","shell.execute_reply":"2025-05-23T22:50:38.066590Z"}},"outputs":[{"execution_count":9,"output_type":"execute_result","data":{"text/plain":"                                                 review  rating\n1860  “فاشل انحشوا منه ياجماعه والله غلطه سكنت فيه!!...       0\n353   “هادي وراقي”. الموقع ممتاز و هادي والاستقبال ر...       1\n1333  “Bad”. أسوء إقامة فندقية في حياتي... لم يعجبني...       0\n905   جيد جداً. موقع الفندق جيد وقريب جدا من الخدمات...       1\n1289  “very bad”. . الغرفة مليئه بالحشرات والتوصيل م...       0\n...                                                 ...     ...\n1130  “مقبوله”. موقع الفندق والهوداء. النظافة بصراحه...       0\n1294  ضعيف جداً. لا شيء سوى قربه من الحرم. النظافة غ...       0\n860   “نقاهه واستجمام”. النظافة والتنظيم وحسن الاستق...       1\n1459  “انتبة من اسواء فندق تجده في مكه”. ليس هناك شي...       0\n1126  مخيب للأمل. لا شيء. الموقع بعيد عن كل شي، مافي...       0\n\n[2000 rows x 2 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>review</th>\n      <th>rating</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>1860</th>\n      <td>“فاشل انحشوا منه ياجماعه والله غلطه سكنت فيه!!...</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>353</th>\n      <td>“هادي وراقي”. الموقع ممتاز و هادي والاستقبال ر...</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>1333</th>\n      <td>“Bad”. أسوء إقامة فندقية في حياتي... لم يعجبني...</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>905</th>\n      <td>جيد جداً. موقع الفندق جيد وقريب جدا من الخدمات...</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>1289</th>\n      <td>“very bad”. . الغرفة مليئه بالحشرات والتوصيل م...</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>1130</th>\n      <td>“مقبوله”. موقع الفندق والهوداء. النظافة بصراحه...</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>1294</th>\n      <td>ضعيف جداً. لا شيء سوى قربه من الحرم. النظافة غ...</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>860</th>\n      <td>“نقاهه واستجمام”. النظافة والتنظيم وحسن الاستق...</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>1459</th>\n      <td>“انتبة من اسواء فندق تجده في مكه”. ليس هناك شي...</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>1126</th>\n      <td>مخيب للأمل. لا شيء. الموقع بعيد عن كل شي، مافي...</td>\n      <td>0</td>\n    </tr>\n  </tbody>\n</table>\n<p>2000 rows × 2 columns</p>\n</div>"},"metadata":{}}],"execution_count":9},{"cell_type":"code","source":"# Shows count of NaN values for each column\nnan_by_column = final_df.isna().sum()\nprint(\"NaN values by column:\")\nprint(nan_by_column)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-23T22:50:38.068101Z","iopub.execute_input":"2025-05-23T22:50:38.068325Z","iopub.status.idle":"2025-05-23T22:50:38.084359Z","shell.execute_reply.started":"2025-05-23T22:50:38.068283Z","shell.execute_reply":"2025-05-23T22:50:38.083602Z"}},"outputs":[{"name":"stdout","text":"NaN values by column:\nreview    0\nrating    0\ndtype: int64\n","output_type":"stream"}],"execution_count":10},{"cell_type":"markdown","source":"****preproccesing reviews****","metadata":{}},{"cell_type":"code","source":"import re\nimport string\ndef clean_arabic_text(text):\n    if isinstance(text, float) and pd.isna(text):\n        return \"\"\n    \n    # Convert to string if not already\n    text = str(text)\n    \n    # Remove URLs\n    text = re.sub(r'https?://\\S+|www\\.\\S+', ' ', text)\n    \n    # Remove HTML tags\n    text = re.sub(r'<.*?>', ' ', text)\n    \n    # Remove punctuation (keeping Arabic question marks and other relevant marks)\n    arabic_punctuations = '''`÷×؛<>_()*&^%][ـ،/:\"؟.,'{}~¦+|!\"…\"–ـ'''\n    english_punctuations = string.punctuation\n    punctuations_list = arabic_punctuations + english_punctuations\n    translator = str.maketrans('', '', punctuations_list)\n    text = text.translate(translator)\n    \n    # Remove repeating characters (like \"جميييييل\" → \"جميل\")\n    text = re.sub(r'(.)\\1+', r'\\1\\1', text)\n    \n    # Remove extra whitespace\n    text = re.sub(r'\\s+', ' ', text)\n    \n    return text.strip()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-23T22:50:38.085346Z","iopub.execute_input":"2025-05-23T22:50:38.085984Z","iopub.status.idle":"2025-05-23T22:50:38.100281Z","shell.execute_reply.started":"2025-05-23T22:50:38.085956Z","shell.execute_reply":"2025-05-23T22:50:38.099452Z"}},"outputs":[],"execution_count":11},{"cell_type":"code","source":"final_df['preprocessed_text']=final_df['review'].apply(clean_arabic_text)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-23T22:50:38.101223Z","iopub.execute_input":"2025-05-23T22:50:38.101495Z","iopub.status.idle":"2025-05-23T22:50:38.202096Z","shell.execute_reply.started":"2025-05-23T22:50:38.101478Z","shell.execute_reply":"2025-05-23T22:50:38.201131Z"}},"outputs":[],"execution_count":12},{"cell_type":"code","source":"final_df=final_df[['rating','preprocessed_text']]\nfinal_df","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-23T22:50:38.203033Z","iopub.execute_input":"2025-05-23T22:50:38.203313Z","iopub.status.idle":"2025-05-23T22:50:38.215899Z","shell.execute_reply.started":"2025-05-23T22:50:38.203287Z","shell.execute_reply":"2025-05-23T22:50:38.215055Z"}},"outputs":[{"execution_count":13,"output_type":"execute_result","data":{"text/plain":"      rating                                  preprocessed_text\n1860       0  “فاشل انحشوا منه ياجماعه والله غلطه سكنت فيه” ...\n353        1  “هادي وراقي” الموقع ممتاز و هادي والاستقبال را...\n1333       0  “Bad” أسوء إقامة فندقية في حياتي لم يعجبني شيء...\n905        1  جيد جداً موقع الفندق جيد وقريب جدا من الخدمات ...\n1289       0  “very bad” الغرفة مليئه بالحشرات والتوصيل من و...\n...      ...                                                ...\n1130       0  “مقبوله” موقع الفندق والهوداء النظافة بصراحه س...\n1294       0  ضعيف جداً لا شيء سوى قربه من الحرم النظافة غير...\n860        1  “نقاهه واستجمام” النظافة والتنظيم وحسن الاستقب...\n1459       0  “انتبة من اسواء فندق تجده في مكه” ليس هناك شيء...\n1126       0  مخيب للأمل لا شيء الموقع بعيد عن كل شي مافيه خ...\n\n[2000 rows x 2 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>rating</th>\n      <th>preprocessed_text</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>1860</th>\n      <td>0</td>\n      <td>“فاشل انحشوا منه ياجماعه والله غلطه سكنت فيه” ...</td>\n    </tr>\n    <tr>\n      <th>353</th>\n      <td>1</td>\n      <td>“هادي وراقي” الموقع ممتاز و هادي والاستقبال را...</td>\n    </tr>\n    <tr>\n      <th>1333</th>\n      <td>0</td>\n      <td>“Bad” أسوء إقامة فندقية في حياتي لم يعجبني شيء...</td>\n    </tr>\n    <tr>\n      <th>905</th>\n      <td>1</td>\n      <td>جيد جداً موقع الفندق جيد وقريب جدا من الخدمات ...</td>\n    </tr>\n    <tr>\n      <th>1289</th>\n      <td>0</td>\n      <td>“very bad” الغرفة مليئه بالحشرات والتوصيل من و...</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>1130</th>\n      <td>0</td>\n      <td>“مقبوله” موقع الفندق والهوداء النظافة بصراحه س...</td>\n    </tr>\n    <tr>\n      <th>1294</th>\n      <td>0</td>\n      <td>ضعيف جداً لا شيء سوى قربه من الحرم النظافة غير...</td>\n    </tr>\n    <tr>\n      <th>860</th>\n      <td>1</td>\n      <td>“نقاهه واستجمام” النظافة والتنظيم وحسن الاستقب...</td>\n    </tr>\n    <tr>\n      <th>1459</th>\n      <td>0</td>\n      <td>“انتبة من اسواء فندق تجده في مكه” ليس هناك شيء...</td>\n    </tr>\n    <tr>\n      <th>1126</th>\n      <td>0</td>\n      <td>مخيب للأمل لا شيء الموقع بعيد عن كل شي مافيه خ...</td>\n    </tr>\n  </tbody>\n</table>\n<p>2000 rows × 2 columns</p>\n</div>"},"metadata":{}}],"execution_count":13},{"cell_type":"code","source":"from transformers import AutoTokenizer,AutoModelForSequenceClassification\nfrom arabert.preprocess import ArabertPreprocessor\nimport torch\n# import torch_xla\n# import torch_xla.core.xla_model as xm\n# import torch_xla.distributed.parallel_loader as pl\n\n#from .autonotebook import tqdm as notebook_tqdm\n\nmodel_name=\"aubmindlab/bert-large-arabertv02\"\n\ntokenizer = AutoTokenizer.from_pretrained(model_name)\n\nmodel = AutoModelForSequenceClassification.from_pretrained(model_name,\n                                                          num_labels=2)\n\n\n\n\narabert_prep = ArabertPreprocessor(model_name=model_name)\n\n\nfinal_df['preprocessed_text'] = final_df['preprocessed_text'].apply(lambda text: arabert_prep.preprocess(text))\n\n# text = \"ولن نبالغ إذا قلنا: إن هاتف أو كمبيوتر المكتب في زمننا هذا ضروري\"\n# output=arabert_prep.preprocess(text)\n# print(output)=\n# device = xm.xla_device()\n# model = model.to(device)\ndevice= 'cuda'if torch.cuda.is_available else 'cpu'\nmodel=model.to(device)\nprint(device)\nprint(f\"Model has {model.config.num_labels} output classes\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-23T22:52:08.376429Z","iopub.execute_input":"2025-05-23T22:52:08.376932Z","iopub.status.idle":"2025-05-23T22:52:09.830900Z","shell.execute_reply.started":"2025-05-23T22:52:08.376910Z","shell.execute_reply":"2025-05-23T22:52:09.829961Z"}},"outputs":[{"name":"stderr","text":"Some weights of BertForSequenceClassification were not initialized from the model checkpoint at aubmindlab/bert-large-arabertv02 and are newly initialized: ['classifier.bias', 'classifier.weight']\nYou should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n/tmp/ipykernel_35/2442277212.py:23: SettingWithCopyWarning: \nA value is trying to be set on a copy of a slice from a DataFrame.\nTry using .loc[row_indexer,col_indexer] = value instead\n\nSee the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n  final_df['preprocessed_text'] = final_df['preprocessed_text'].apply(lambda text: arabert_prep.preprocess(text))\n","output_type":"stream"},{"name":"stdout","text":"cuda\nModel has 2 output classes\n","output_type":"stream"}],"execution_count":17},{"cell_type":"code","source":"from torch.utils.data import Dataset\nfrom sklearn.model_selection import train_test_split\nimport torch\nclass ArabicSentimentDataset(Dataset):\n    def __init__(self, texts, labels, tokenizer, max_length=128):\n        self.texts = texts\n        self.labels = labels\n        self.tokenizer = tokenizer\n        self.max_length = max_length\n        \n    def __len__(self):\n        return len(self.texts)\n    \n    def __getitem__(self, idx):\n        text = str(self.texts[idx])\n        label = self.labels[idx]\n        \n        encoding = self.tokenizer(\n            text,\n            add_special_tokens=True,\n            max_length=self.max_length,\n            truncation=True,\n            padding='max_length',\n            return_tensors='pt'\n        )\n        \n        return {\n            'input_ids': encoding['input_ids'].flatten(),\n            'attention_mask': encoding['attention_mask'].flatten(),\n            'labels': torch.tensor(label, dtype=torch.long)\n        }\n\n\n\n# First split out the test set\ntrain_val_texts, test_texts, train_val_labels, test_labels = train_test_split(\n    final_df['preprocessed_text'].tolist(),\n    final_df['rating'].tolist(),\n    test_size=0.15,  # 15% for test set\n    random_state=42\n)\n\n# Then split the remaining data into train and validation\ntrain_texts, val_texts, train_labels, val_labels = train_test_split(\n    train_val_texts,\n    train_val_labels,\n    test_size=0.176,  # 0.176 × 0.85 ≈ 0.15 (15% of all data data)\n    random_state=42\n)\n\n# Create datasets\ntrain_dataset = ArabicSentimentDataset(train_texts, train_labels, tokenizer)\nval_dataset = ArabicSentimentDataset(val_texts, val_labels, tokenizer)\ntest_dataset = ArabicSentimentDataset(test_texts, test_labels, tokenizer)\n\nprint(f\"Train dataset size: {len(train_dataset)}\")\nprint(f\"Validation dataset size: {len(val_dataset)}\")\nprint(f\"Test dataset size: {len(test_dataset)}\")\nprint(train_dataset.__getitem__(0))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-23T22:52:12.081425Z","iopub.execute_input":"2025-05-23T22:52:12.082058Z","iopub.status.idle":"2025-05-23T22:52:12.101422Z","shell.execute_reply.started":"2025-05-23T22:52:12.082037Z","shell.execute_reply":"2025-05-23T22:52:12.100774Z"}},"outputs":[{"name":"stdout","text":"Train dataset size: 1400\nValidation dataset size: 300\nTest dataset size: 300\n{'input_ids': tensor([    2,   174,  7034, 50547,   195,  8899, 10984,   175, 16793,   407,\n         2105,  8980,     3,     0,     0,     0,     0,     0,     0,     0,\n            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n            0,     0,     0,     0,     0,     0,     0,     0]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n        0, 0, 0, 0, 0, 0, 0, 0]), 'labels': tensor(1)}\n","output_type":"stream"}],"execution_count":18},{"cell_type":"code","source":"from sklearn.metrics import confusion_matrix, precision_recall_fscore_support,accuracy_score  \ndef compute_acc(eval_pred):\n    \n    predicts=eval_pred.predictions.argmax(-1)\n    labels=eval_pred.label_ids\n    acc=accuracy_score(labels,predicts)\n    return {\"accuracy\": acc}\n    ","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-23T22:52:14.549615Z","iopub.execute_input":"2025-05-23T22:52:14.549930Z","iopub.status.idle":"2025-05-23T22:52:14.554846Z","shell.execute_reply.started":"2025-05-23T22:52:14.549909Z","shell.execute_reply":"2025-05-23T22:52:14.553889Z"}},"outputs":[],"execution_count":19},{"cell_type":"code","source":"steps=len(train_dataset)/16*3\nwarmup_ratio=steps/10\nwarmup_ratio","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-23T22:52:14.799218Z","iopub.execute_input":"2025-05-23T22:52:14.799752Z","iopub.status.idle":"2025-05-23T22:52:14.804774Z","shell.execute_reply.started":"2025-05-23T22:52:14.799699Z","shell.execute_reply":"2025-05-23T22:52:14.804192Z"}},"outputs":[{"execution_count":20,"output_type":"execute_result","data":{"text/plain":"26.25"},"metadata":{}}],"execution_count":20},{"cell_type":"code","source":"\nimport wandb\nfrom kaggle_secrets import UserSecretsClient\nuser_secrets = UserSecretsClient()\nsecret_value_0 = user_secrets.get_secret(\"wandb_key\")\nwandb.login(key = secret_value_0)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-23T22:52:19.769292Z","iopub.execute_input":"2025-05-23T22:52:19.769639Z","iopub.status.idle":"2025-05-23T22:52:28.960496Z","shell.execute_reply.started":"2025-05-23T22:52:19.769621Z","shell.execute_reply":"2025-05-23T22:52:28.959739Z"}},"outputs":[{"name":"stderr","text":"\u001b[34m\u001b[1mwandb\u001b[0m: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m If you're specifying your api key in code, ensure this code is not shared publicly.\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Consider setting the WANDB_API_KEY environment variable, or running `wandb login` from the command line.\n\u001b[34m\u001b[1mwandb\u001b[0m: No netrc file found, creating one.\n\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mbasem-yasser\u001b[0m to \u001b[32mhttps://api.wandb.ai\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n","output_type":"stream"},{"execution_count":22,"output_type":"execute_result","data":{"text/plain":"True"},"metadata":{}}],"execution_count":22},{"cell_type":"code","source":"from transformers import TrainingArguments, Trainer\n\ntraining_args = TrainingArguments(\n    \n    output_dir='./arabic_llm',\n    num_train_epochs=3,\n    per_device_train_batch_size=16,\n    per_device_eval_batch_size=32,\n    learning_rate= 3e-5,\n    metric_for_best_model=\"accuracy\",\n    report_to=\"wandb\",\n    lr_scheduler_type=\"linear\",\n    warmup_steps=26,\n    weight_decay=0.01,\n    logging_dir='./logs',\n    logging_steps=8,\n    eval_strategy=\"epoch\",\n    save_strategy=\"epoch\",\n    save_total_limit=2,\n    load_best_model_at_end=True,\n)\n\ntrainer = Trainer(\n    model=model,\n    args=training_args,\n    train_dataset=train_dataset,\n    eval_dataset=test_dataset,\n    compute_metrics=compute_acc\n)\n\n\ntrain_result = trainer.train()\ntrain_loss = train_result.training_loss\nprint(f\"Final Training Loss: {train_loss}\")\n# 9. Evaluate on the test set\nfinal_metrics = trainer.evaluate()\nprint(f\"Final evaluation metrics: {final_metrics}\")\n\n# 10. Save the model\nmodel_path = \"./results\"\nmodel.save_pretrained(model_path)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-23T22:52:31.216080Z","iopub.execute_input":"2025-05-23T22:52:31.216758Z","iopub.status.idle":"2025-05-23T22:56:28.572490Z","shell.execute_reply.started":"2025-05-23T22:52:31.216731Z","shell.execute_reply":"2025-05-23T22:56:28.571261Z"}},"outputs":[{"name":"stderr","text":"\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m The `run_name` is currently set to the same value as `TrainingArguments.output_dir`. If this was not intended, please specify a different run name by setting the `TrainingArguments.run_name` parameter.\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Tracking run with wandb version 0.19.9"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Run data is saved locally in <code>/kaggle/working/wandb/run-20250523_225234-a623rrzd</code>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Syncing run <strong><a href='https://wandb.ai/basem-yasser/huggingface/runs/a623rrzd' target=\"_blank\">./arabic_llm</a></strong> to <a href='https://wandb.ai/basem-yasser/huggingface' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View project at <a href='https://wandb.ai/basem-yasser/huggingface' target=\"_blank\">https://wandb.ai/basem-yasser/huggingface</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View run at <a href='https://wandb.ai/basem-yasser/huggingface/runs/a623rrzd' target=\"_blank\">https://wandb.ai/basem-yasser/huggingface/runs/a623rrzd</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='264' max='264' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [264/264 03:40, Epoch 3/3]\n    </div>\n    <table border=\"1\" class=\"dataframe\">\n  <thead>\n <tr style=\"text-align: left;\">\n      <th>Epoch</th>\n      <th>Training Loss</th>\n      <th>Validation Loss</th>\n      <th>Accuracy</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>1</td>\n      <td>0.626600</td>\n      <td>0.606603</td>\n      <td>0.620000</td>\n    </tr>\n    <tr>\n      <td>2</td>\n      <td>0.298000</td>\n      <td>0.201836</td>\n      <td>0.933333</td>\n    </tr>\n    <tr>\n      <td>3</td>\n      <td>0.315900</td>\n      <td>0.220011</td>\n      <td>0.930000</td>\n    </tr>\n  </tbody>\n</table><p>"},"metadata":{}},{"name":"stdout","text":"Final Training Loss: 0.4226076625513308\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='10' max='10' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [10/10 00:03]\n    </div>\n    "},"metadata":{}},{"name":"stdout","text":"Final evaluation metrics: {'eval_loss': 0.20183619856834412, 'eval_accuracy': 0.9333333333333333, 'eval_runtime': 3.7646, 'eval_samples_per_second': 79.689, 'eval_steps_per_second': 2.656, 'epoch': 3.0}\n","output_type":"stream"},{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m/tmp/ipykernel_35/3166090640.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     40\u001b[0m \u001b[0mmodel_path\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"./results\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     41\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave_pretrained\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 42\u001b[0;31m \u001b[0mfeature_extractor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave_pretrained\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;31mNameError\u001b[0m: name 'feature_extractor' is not defined"],"ename":"NameError","evalue":"name 'feature_extractor' is not defined","output_type":"error"}],"execution_count":23},{"cell_type":"code","source":"loaded_model = AutoModelForSequenceClassification.from_pretrained(model_path)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-23T22:59:45.409450Z","iopub.execute_input":"2025-05-23T22:59:45.409818Z","iopub.status.idle":"2025-05-23T22:59:45.658460Z","shell.execute_reply.started":"2025-05-23T22:59:45.409794Z","shell.execute_reply":"2025-05-23T22:59:45.657858Z"}},"outputs":[],"execution_count":24},{"cell_type":"code","source":"from transformers import pipeline\n\n# After training your model:\nclassifier = pipeline(\n    \"sentiment-analysis\",\n    model=loaded_model,\n    tokenizer=tokenizer\n)\n\n# Then use it like:\nresult1 = classifier('الفندق وحش اوي لا انصح به')\nresult2 = classifier('روعة')\nresult3 = classifier('والله المكان مش نظيف ')\n\nprint(result1)\nprint(result2)\nprint(result3)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-23T23:03:25.005211Z","iopub.execute_input":"2025-05-23T23:03:25.005516Z","iopub.status.idle":"2025-05-23T23:03:25.073336Z","shell.execute_reply.started":"2025-05-23T23:03:25.005493Z","shell.execute_reply":"2025-05-23T23:03:25.072625Z"}},"outputs":[{"name":"stderr","text":"Device set to use cuda:0\n","output_type":"stream"},{"name":"stdout","text":"[{'label': 'LABEL_0', 'score': 0.9898926615715027}]\n[{'label': 'LABEL_1', 'score': 0.8486823439598083}]\n[{'label': 'LABEL_0', 'score': 0.9404568672180176}]\n","output_type":"stream"}],"execution_count":31},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}